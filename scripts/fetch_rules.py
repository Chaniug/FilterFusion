import json
import requests
import hashlib
import sys
from datetime import datetime, timezone
from pathlib import Path

class RuleFetcher:
    def __init__(self):
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = Path(__file__).resolve().parent.parent
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        
        self.rules_dir = self.project_root / 'rules'
        self.rules_dir.mkdir(parents=True, exist_ok=True)
        self.meta_file = self.rules_dir / 'fetch_meta.json'
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"è§„åˆ™ç›®å½•: {self.rules_dir}")
        
    def load_sources(self):
        try:
            config_path = self.project_root / 'config' / 'sources.json'
            
            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            print(f"é…ç½®æ–‡ä»¶è·¯å¾„: {config_path}")
            
            if not config_path.exists():
                print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {config_path}")
                sys.exit(1)
                
            with open(config_path, 'r') as f:
                data = json.load(f)
                print(f"åŠ è½½äº† {len(data['sources'])} ä¸ªè§„åˆ™æº")
                return data['sources']
        except FileNotFoundError:
            print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° sources.json é…ç½®æ–‡ä»¶")
            sys.exit(1)
        except json.JSONDecodeError:
            print("âŒ é”™è¯¯ï¼šsources.json é…ç½®æ ¼å¼ä¸æ­£ç¡®")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            sys.exit(1)
    
    def fetch_single_rule(self, source):
        retry_count = 3
        for attempt in range(1, retry_count + 1):
            try:
                print(f"â¬‡ï¸  æŠ“å–è§„åˆ™: {source['name']} (å°è¯• {attempt}/{retry_count})...", end=' ', flush=True)
                # å¢åŠ è¶…æ—¶æ—¶é—´
                timeout = 10 + attempt * 5
                response = requests.get(source['url'], timeout=timeout)
                response.raise_for_status()
                
                # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
                safe_name = source['name'].replace(' ', '_').lower().replace('.', '')
                filename = f"{safe_name}.txt"
                filepath = self.rules_dir / filename
                
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                
                file_hash = hashlib.sha256(response.content).hexdigest()
                timestamp = datetime.now(timezone.utc).isoformat()
                
                print("âœ“")
                return {
                    "name": source['name'],
                    "file": filename,
                    "url": source['url'],
                    "timestamp": timestamp,
                    "hash": file_hash,
                    "status": "success"
                }
            except requests.exceptions.Timeout:
                if attempt < retry_count:
                    print("è¶…æ—¶ï¼Œé‡è¯•...", end=' ')
                else:
                    print("âœ— (è¶…æ—¶)")
                    return {
                        "name": source['name'],
                        "url": source['url'],
                        "status": "failed",
                        "error": "è¯·æ±‚è¶…æ—¶",
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }
            except requests.exceptions.RequestException as e:
                if attempt < retry_count:
                    print(f"é”™è¯¯ ({str(e)}), é‡è¯•...", end=' ')
                else:
                    print(f"âœ— ({str(e)})")
                    return {
                        "name": source['name'],
                        "url": source['url'],
                        "status": "failed",
                        "error": str(e),
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }
    
    def fetch_all_rules(self):
        sources = self.load_sources()
        results = []
        
        print("\n" + "="*50)
        print("ğŸ” å¼€å§‹æŠ“å–å¹¿å‘Šè¿‡æ»¤è§„åˆ™...")
        print(f"ğŸ“¡ å…±æ£€æµ‹åˆ° {len(sources)} ä¸ªè§„åˆ™æº")
        print("="*50)
        
        for source in sources:
            if not source.get('enabled', True):
                print(f"â­ï¸  è·³è¿‡ç¦ç”¨è§„åˆ™: {source['name']}")
                continue
            result = self.fetch_single_rule(source)
            results.append(result)
        
        # ä¿å­˜å…ƒæ•°æ®
        meta = {
            "fetch_date": datetime.now(timezone.utc).isoformat(),
            "sources": results
        }
        
        with open(self.meta_file, 'w') as f:
            json.dump(meta, f, indent=2)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        success = sum(1 for s in results if s['status'] == 'success')
        failed = sum(1 for s in results if s['status'] == 'failed')
        
        print("\n" + "="*50)
        print(f"âœ… æŠ“å–å®Œæˆ: æˆåŠŸ {success} ä¸ª, å¤±è´¥ {failed} ä¸ª")
        print("="*50)
        
        if failed > 0:
            print("\nå¤±è´¥çš„æ¥æº:")
            for source in results:
                if source['status'] == 'failed':
                    print(f"  - {source['name']}: {source.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        print(f"æŠ“å–å…ƒæ•°æ®å·²ä¿å­˜è‡³: {self.meta_file}")
        return meta

if __name__ == "__main__":
    print("="*50)
    print("ğŸš€ FilterFusion - å¹¿å‘Šè§„åˆ™æŠ“å–å·¥å…·")
    print("="*50)
    
    fetcher = RuleFetcher()
    try:
        metadata = fetcher.fetch_all_rules()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        sys.exit(1)