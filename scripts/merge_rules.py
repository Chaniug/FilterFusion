import json
import hashlib
import sys
import shutil
import re
import unicodedata
from datetime import datetime, timezone
from pathlib import Path
from collections import defaultdict

class RuleMerger:
    def __init__(self):
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = Path(__file__).resolve().parent.parent
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")

        self.dist_dir = self.project_root / 'dist'
        self.dist_dir.mkdir(parents=True, exist_ok=True)
        self.rules_dir = self.project_root / 'rules'

        print(f"åˆ†å‘ç›®å½•: {self.dist_dir}")
        print(f"è§„åˆ™ç›®å½•: {self.rules_dir}")

        # ç»Ÿè®¡ä¿¡æ¯
        self.initial_rule_count = 0
        self.final_rule_count = 0
        self.start_time = datetime.now()

    def load_metadata(self):
        # è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        meta_path = self.rules_dir / 'fetch_meta.json'
        print(f"å°è¯•åŠ è½½å…ƒæ•°æ®: {meta_path}")

        if not meta_path.exists():
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æŠ“å–å…ƒæ•°æ®æ–‡ä»¶ {meta_path}")
            sys.exit(1)

        try:
            with open(meta_path, 'r') as f:
                print("æˆåŠŸåŠ è½½å…ƒæ•°æ®æ–‡ä»¶")
                return json.load(f)
        except json.JSONDecodeError as e:
            print(f"âŒ é”™è¯¯ï¼šå…ƒæ•°æ®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡® {e}")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åŠ è½½å…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            sys.exit(1)

    def load_header_template(self):
        # è·å–å¤´éƒ¨æ¨¡æ¿è·¯å¾„
        header_path = self.project_root / 'config' / 'default.header'
        print(f"å°è¯•åŠ è½½å¤´éƒ¨æ¨¡æ¿: {header_path}")

        if not header_path.exists():
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¤´éƒ¨æ¨¡æ¿ {header_path}")
            print("è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨:")
            print(f"ä½ç½®: {header_path}")
            print("æ–‡ä»¶å†…å®¹åº”ä¸º:")
            print("-" * 50)
            print('''! Title: FilterFusion AdBlock Rules
! Version: {VERSION}
! Updated: {TIMEUPDATED}
! Last modified: {TIMEUPDATED}
! Checksum: {CHECKSUM}
! Homepage: {HOMEPAGE}
! Expires: 1 day
! License: {LICENSE}''')
            print("-" * 50)
            sys.exit(1)

        try:
            with open(header_path, 'r') as f:
                print("æˆåŠŸåŠ è½½å¤´éƒ¨æ¨¡æ¿")
                return f.read()
        except Exception as e:
            print(f"âŒ è¯»å–å¤´éƒ¨æ¨¡æ¿å¤±è´¥: {str(e)}")
            sys.exit(1)

    def generate_source_list(self, sources):
        """ç”Ÿæˆæ ¼å¼åŒ–çš„æºåˆ—è¡¨ä¿¡æ¯"""
        source_info = []
        for source in sources:
            status_icon = "âœ“" if source.get('status') == 'success' else "âœ—"
            source_info.append(f"! - {status_icon} {source['name']} (æ›´æ–°: {source['timestamp'][:10]})")
        return "\n".join(source_info)

    def calculate_source_stats(self, sources):
        """è®¡ç®—æºè§„åˆ™ç»Ÿè®¡æ•°æ®"""
        source_stats = []
        rule_counts = defaultdict(int)

        print("è®¡ç®—æºè§„åˆ™ç»Ÿè®¡:")
        for source in sources:
            if source.get('status') != 'success':
                continue

            source_path = self.rules_dir / source['file']
            print(f"å¤„ç†æº: {source['name']}")
            print(f"æ–‡ä»¶è·¯å¾„: {source_path}")

            if not source_path.exists():
                print(f"æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
                continue

            try:
                with open(source_path, 'r', encoding='utf-8') as f:
                    rule_count = 0
                    for line in f:
                        stripped = line.strip()
                        if stripped and not stripped.startswith(('!', '#', '[Adblock')):
                            rule_count += 1
                    print(f"æº {source['name']} è§„åˆ™æ•°: {rule_count}")
                    source_stats.append({
                        "name": source['name'],
                        "rule_count": rule_count
                    })
                    rule_counts[source['name']] = rule_count
            except UnicodeDecodeError:
                print(f"âš ï¸ è­¦å‘Šï¼šè§„åˆ™æ–‡ä»¶ {source['file']} ç¼–ç é—®é¢˜")
                source_stats.append({
                    "name": source['name'],
                    "rule_count": 0
                })

        print("æºç»Ÿè®¡å®Œæˆ")
        return source_stats, rule_counts

    def process_rule(self, line):
        """
        å¯¹å•æ¡è§„åˆ™è¿›è¡Œè§„èŒƒåŒ–ã€åˆ†ç»„å’Œå…¼å®¹æ€§å¤„ç†ï¼Œè¿”å› (type, rule)ã€‚
        type: normal/exception/html_filter/regex/special/comment
        """
        # å»é™¤ä¸å¯è§å­—ç¬¦å’Œå¤šä½™ç©ºç™½
        rule = unicodedata.normalize('NFKC', line.strip())
        if not rule:
            return (None, None)
        # æ³¨é‡Š
        if rule.startswith('!') or rule.startswith('#'):
            return ('comment', rule)
        # æ­£åˆ™ (å¦‚ /adunion.*/ æˆ– /xxx/[flags])
        if re.match(r"^\/.+\/[a-zA-Z0-9]*$", rule):
            return ('regex', rule)
        # AdGuardæ‰©å±•è¯­æ³•/HTML/scriptletç­‰
        if any(k in rule for k in [
            "#%#", "#@#", "#$#", "#@$#", "#?#",
            "$removeparam=", "$cookie=", "$redirect=",
            "$generichide", "scriptlet(", "jsinject"
        ]):
            return ('html_filter', rule)
        # ä¾‹å¤–è§„åˆ™ (@@)
        if rule.startswith('@@'):
            return ('exception', rule)
        # uBlock/AdGuardç‰¹æ®Šå‚æ•°
        if any(k in rule for k in [
            "$badfilter", "$important", "$app=", "$domain=", "$csp=", "$replace="
        ]):
            return ('special', rule)
        # æ™®é€šå±è”½
        return ('normal', rule)

    def collect_and_process_rules(self, sources, rule_counts):
        """
        æ”¶é›†å¹¶å¤„ç†è§„åˆ™ï¼Œè¯­æ³•åˆ†ç»„ã€æ ¼å¼è§„èŒƒã€æ‰©å±•å…¼å®¹
        è¿”å›: merged_lines, groups
        """
        # åˆ†ç»„å®¹å™¨
        groups = {
            'normal': set(),
            'exception': set(),
            'html_filter': set(),
            'regex': set(),
            'special': set(),
            'comment': set()
        }
        seen_rules = set()
        print("æ”¶é›†å’Œå¤„ç†è§„åˆ™:")
        for source in sources:
            if source.get('status') != 'success' or rule_counts.get(source['name'], 0) == 0:
                continue
            source_path = self.rules_dir / source['file']
            print(f"å¤„ç†æºæ–‡ä»¶: {source_path}")
            if not source_path.exists():
                continue
            try:
                with open(source_path, 'r', encoding='utf-8', errors='replace') as f:
                    for line in f:
                        typ, rule = self.process_rule(line)
                        if not rule or (typ == 'comment' and rule in groups['comment']):
                            continue
                        # æ³¨é‡Šåªä¿ç•™å‰10æ¡
                        if typ == 'comment':
                            if len(groups['comment']) < 10:
                                groups['comment'].add(rule)
                            continue
                        # å…¶ä½™ç±»å‹åšå…¨å±€å”¯ä¸€å»é‡
                        rule_id = f"{typ}:{rule}"
                        if rule_id in seen_rules:
                            continue
                        seen_rules.add(rule_id)
                        groups[typ].add(rule)
            except Exception as e:
                print(f"âš ï¸ è­¦å‘Šï¼šå¤„ç† {source['name']} è§„åˆ™æ—¶å‡ºé”™: {str(e)}")

        # è¾“å‡ºæ—¶æŒ‰åˆ†ç»„åˆ†ç±»æ‹¼æ¥ï¼ˆå»æ‰æ³¨é‡Šåˆ†ç»„ï¼‰
        merged_lines = []
        # æ³¨é‡Šåˆ†ç»„å·²å»é™¤ä¸è¾“å‡º
        if groups['exception']:
            merged_lines.append("! === ä¾‹å¤–è§„åˆ™ Exception Rules ===")
            merged_lines.extend(sorted(groups['exception']))
            merged_lines.append("")
        if groups['html_filter']:
            merged_lines.append("! === AdGuard/HTML Scriptlet Rules ===")
            merged_lines.extend(sorted(groups['html_filter']))
            merged_lines.append("")
        if groups['regex']:
            merged_lines.append("! === æ­£åˆ™è§„åˆ™ Regex Rules ===")
            merged_lines.extend(sorted(groups['regex']))
            merged_lines.append("")
        if groups['special']:
            merged_lines.append("! === ç‰¹æ®Šå‚æ•°/å®éªŒæ€§è§„åˆ™ Special/Experimental ===")
            merged_lines.extend(sorted(groups['special']))
            merged_lines.append("")
        if groups['normal']:
            merged_lines.append("! === å±è”½è§„åˆ™ Blocking Rules ===")
            merged_lines.extend(sorted(groups['normal']))
            merged_lines.append("")

        print(f"æ”¶é›†äº† {sum(len(v) for k, v in groups.items() if k != 'comment')} æ¡å”¯ä¸€è§„åˆ™")
        return merged_lines, groups

    def generate_version(self):
        """ç”Ÿæˆç®€å•çš„è¯­ä¹‰åŒ–ç‰ˆæœ¬å·"""
        today = datetime.now(timezone.utc)
        return f"{today.year}{today.month:02d}{today.day:02d}"

    def merge(self):
        print("="*50)
        print("ğŸ”§ FilterFusion - å¹¿å‘Šè§„åˆ™åˆå¹¶å·¥å…·")
        print("="*50)

        # åŠ è½½æ•°æ®
        print("æ­¥éª¤1: åŠ è½½å…ƒæ•°æ®")
        metadata = self.load_metadata()
        sources = metadata['sources']

        print("æ­¥éª¤2: åŠ è½½å¤´éƒ¨æ¨¡æ¿")
        header_template = self.load_header_template()

        print("æ­¥éª¤3: è®¡ç®—æºè§„åˆ™ç»Ÿè®¡")
        source_stats, rule_counts = self.calculate_source_stats(sources)
        self.initial_rule_count = sum(rule_counts.values())

        print("æ­¥éª¤4: æ”¶é›†å’Œå¤„ç†è§„åˆ™")
        rules, groups = self.collect_and_process_rules(sources, rule_counts)
        self.final_rule_count = sum(len(v) for k, v in groups.items() if k != 'comment')

        print("æ­¥éª¤5: ç”Ÿæˆç‰ˆæœ¬å·")
        version = self.generate_version()

        print("æ­¥éª¤6: ç”Ÿæˆå¤´éƒ¨")
        source_list = self.generate_source_list(sources)
        header = header_template \
            .replace('{VERSION}', version) \
            .replace('{TIMEUPDATED}', datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')) \
            .replace('{SOURCE_COUNT}', str(len([s for s in sources if s.get('status') == 'success']))) \
            .replace('{SOURCE_LIST}', source_list) \
            .replace('{RULE_COUNT}', str(self.final_rule_count)) \
            .replace('{HOMEPAGE}', "https://github.com/Chaniug/FilterFusion") \
            .replace('{LICENSE}', "MIT License")

        # æ„å»ºæœ€ç»ˆå†…å®¹
        content = header
        content += f"! Combined rules: {self.final_rule_count}\n"
        content += f"! Total rules: {self.initial_rule_count}\n"
        content += f"! Repetitions: {self.initial_rule_count - self.final_rule_count}\n\n"
        content += "\n".join(rules)

        # è®¡ç®—æ ¡éªŒå’Œ
        print("æ­¥éª¤7: è®¡ç®—æ ¡éªŒå’Œ")
        checksum = hashlib.sha256(content.encode('utf-8')).hexdigest()
        content = content.replace('{CHECKSUM}', checksum)

        # ä¿å­˜è§„åˆ™æ–‡ä»¶
        rule_filename = f"adblock-{version}.txt"
        rule_path = self.dist_dir / rule_filename
        print(f"ä¿å­˜è§„åˆ™æ–‡ä»¶åˆ°: {rule_path}")
        with open(rule_path, 'w', encoding='utf-8') as f:
            f.write(content)

        # ä¿å­˜æœ€æ–°è§„åˆ™å‰¯æœ¬ï¼ˆæœ€ä½³å®è·µï¼šç›´æ¥å¤åˆ¶å†…å®¹è€Œéç¬¦å·é“¾æ¥ï¼‰
        print("æ­¥éª¤8: ä¿å­˜æœ€æ–°è§„åˆ™å‰¯æœ¬")
        main_path = self.dist_dir / "adblock-main.txt"
        if main_path.exists():
            main_path.unlink()
        shutil.copyfile(rule_path, main_path)  # ç›´æ¥å¤åˆ¶æ–‡ä»¶å†…å®¹

        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = (datetime.now() - self.start_time).total_seconds()

        # æ˜¾ç¤ºæ‘˜è¦
        print("\n" + "="*50)
        print("âœ… è§„åˆ™åˆå¹¶å®Œæˆ!")
        print("="*50)
        print(f"ğŸ”– ç‰ˆæœ¬: {version}")
        print(f"ğŸ“¦ æºè§„åˆ™æ•°é‡: {self.initial_rule_count}")
        print(f"ğŸª„ åˆå¹¶åè§„åˆ™æ•°é‡: {self.final_rule_count}")
        print(f"â™»ï¸  é‡å¤è§„åˆ™: {self.initial_rule_count - self.final_rule_count}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        print(f"ğŸ” æ ¡éªŒå’Œ: {checksum[:16]}...{checksum[-16:]}")
        print(f"ğŸ“„ åˆå¹¶è§„åˆ™æ–‡ä»¶: dist/{rule_filename}")
        print(f"ğŸ“„ æœ€æ–°è§„åˆ™å‰¯æœ¬: dist/adblock-main.txt")

        # ä¿å­˜æ‘˜è¦ä¿¡æ¯
        print("æ­¥éª¤9: ä¿å­˜æ‘˜è¦ä¿¡æ¯")
        self.save_summary(version, checksum, source_stats, processing_time)

    def save_summary(self, version, checksum, source_stats, processing_time):
        """ä¿å­˜æ‘˜è¦ä¿¡æ¯åˆ° JSON æ–‡ä»¶"""
        summary = {
            "date": datetime.now(timezone.utc).isoformat(),
            "version": version,
            "sources": source_stats,
            "stats": {
                "initial_rules": self.initial_rule_count,
                "final_rules": self.final_rule_count,
                "duplicates": self.initial_rule_count - self.final_rule_count,
                "processing_time_sec": processing_time,
                "checksum": checksum
            }
        }

        summary_path = self.dist_dir / "summary.json"
        print(f"ä¿å­˜æ‘˜è¦åˆ°: {summary_path}")
        with open(summary_path, 'w') as f:
            json.dump(summary, f, indent=2)

        print(f"ğŸ“Š æ‘˜è¦ä¿¡æ¯å·²ä¿å­˜è‡³: dist/summary.json")

if __name__ == "__main__":
    merger = RuleMerger()
    try:
        merger.merge()
    except Exception as e:
        print(f"âŒ åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯: {str(e)}")
        sys.exit(1)
