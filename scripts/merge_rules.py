import json
import hashlib
import sys
from datetime import datetime, timezone
from pathlib import Path
from collections import defaultdict

class RuleMerger:
    def __init__(self):
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = Path(__file__).resolve().parent.parent
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        
        self.dist_dir = self.project_root / 'dist'
        self.dist_dir.mkdir(parents=True, exist_ok=True)
        self.rules_dir = self.project_root / 'rules'
        
        print(f"åˆ†å‘ç›®å½•: {self.dist_dir}")
        print(f"è§„åˆ™ç›®å½•: {self.rules_dir}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.initial_rule_count = 0
        self.final_rule_count = 0
        self.start_time = datetime.now()
        
    def load_metadata(self):
        # è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        meta_path = self.rules_dir / 'fetch_meta.json'
        print(f"å°è¯•åŠ è½½å…ƒæ•°æ®: {meta_path}")
        
        if not meta_path.exists():
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æŠ“å–å…ƒæ•°æ®æ–‡ä»¶ {meta_path}")
            sys.exit(1)
            
        try:
            with open(meta_path, 'r') as f:
                print("æˆåŠŸåŠ è½½å…ƒæ•°æ®æ–‡ä»¶")
                return json.load(f)
        except json.JSONDecodeError as e:
            print(f"âŒ é”™è¯¯ï¼šå…ƒæ•°æ®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡® {e}")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åŠ è½½å…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            sys.exit(1)
    
    def load_header_template(self):
        # è·å–å¤´éƒ¨æ¨¡æ¿è·¯å¾„
        header_path = self.project_root / 'config' / 'default.header'
        print(f"å°è¯•åŠ è½½å¤´éƒ¨æ¨¡æ¿: {header_path}")
        
        if not header_path.exists():
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¤´éƒ¨æ¨¡æ¿ {header_path}")
            print("è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨:")
            print(f"ä½ç½®: {header_path}")
            print("æ–‡ä»¶å†…å®¹åº”ä¸º:")
            print("-" * 50)
            print('''! Title: FilterFusion AdBlock Rules
! Version: {VERSION}
! Updated: {TIMEUPDATED}
! Last modified: {TIMEUPDATED}
! Checksum: {CHECKSUM}
! Homepage: {HOMEPAGE}
! Expires: 1 day
! License: {LICENSE}''')
            print("-" * 50)
            sys.exit(1)
            
        try:
            with open(header_path, 'r') as f:
                print("æˆåŠŸåŠ è½½å¤´éƒ¨æ¨¡æ¿")
                return f.read()
        except Exception as e:
            print(f"âŒ è¯»å–å¤´éƒ¨æ¨¡æ¿å¤±è´¥: {str(e)}")
            sys.exit(1)
    
    def generate_source_list(self, sources):
        """ç”Ÿæˆæ ¼å¼åŒ–çš„æºåˆ—è¡¨ä¿¡æ¯"""
        source_info = []
        for source in sources:
            status_icon = "âœ“" if source.get('status') == 'success' else "âœ—"
            source_info.append(f"! - {status_icon} {source['name']} (æ›´æ–°: {source['timestamp'][:10]})")
        return "\n".join(source_info)
    
    def calculate_source_stats(self, sources):
        """è®¡ç®—æºè§„åˆ™ç»Ÿè®¡æ•°æ®"""
        source_stats = []
        rule_counts = defaultdict(int)
        
        print("è®¡ç®—æºè§„åˆ™ç»Ÿè®¡:")
        for source in sources:
            if source.get('status') != 'success':
                continue
                
            source_path = self.rules_dir / source['file']
            print(f"å¤„ç†æº: {source['name']}")
            print(f"æ–‡ä»¶è·¯å¾„: {source_path}")
            
            if not source_path.exists():
                print(f"æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
                continue
                
            try:
                with open(source_path, 'r', encoding='utf-8') as f:
                    rule_count = 0
                    for line in f:
                        stripped = line.strip()
                        if stripped and not stripped.startswith(('!', '#', '[Adblock')):
                            rule_count += 1
                    print(f"æº {source['name']} è§„åˆ™æ•°: {rule_count}")
                    source_stats.append({
                        "name": source['name'],
                        "rule_count": rule_count
                    })
                    rule_counts[source['name']] = rule_count
            except UnicodeDecodeError:
                print(f"âš ï¸ è­¦å‘Šï¼šè§„åˆ™æ–‡ä»¶ {source['file']} ç¼–ç é—®é¢˜")
                source_stats.append({
                    "name": source['name'],
                    "rule_count": 0
                })
        
        print("æºç»Ÿè®¡å®Œæˆ")
        return source_stats, rule_counts
    
    def collect_and_process_rules(self, sources, rule_counts):
        """æ”¶é›†å¹¶å¤„ç†è§„åˆ™"""
        all_rules = []
        seen_rules = set()
        
        print("æ”¶é›†å’Œå¤„ç†è§„åˆ™:")
        for source in sources:
            if source.get('status') != 'success' or rule_counts.get(source['name'], 0) == 0:
                continue
                
            source_path = self.rules_dir / source['file']
            print(f"å¤„ç†æºæ–‡ä»¶: {source_path}")
            
            if not source_path.exists():
                continue
                
            try:
                with open(source_path, 'r', encoding='utf-8', errors='replace') as f:
                    for line in f:
                        stripped = line.strip()
                        # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                        if not stripped or stripped.startswith('!') or stripped.startswith('#'):
                            continue
                            
                        # ç®€å•å»é‡
                        if stripped in seen_rules:
                            continue
                            
                        seen_rules.add(stripped)
                        all_rules.append(stripped)
            except Exception as e:
                print(f"âš ï¸ è­¦å‘Šï¼šå¤„ç† {source['name']} è§„åˆ™æ—¶å‡ºé”™: {str(e)}")
        
        print(f"æ”¶é›†äº† {len(all_rules)} æ¡å”¯ä¸€è§„åˆ™")
        return all_rules
    
    def generate_version(self):
        """ç”Ÿæˆç®€å•çš„è¯­ä¹‰åŒ–ç‰ˆæœ¬å·"""
        today = datetime.now(timezone.utc)
        return f"{today.year}{today.month:02d}{today.day:02d}"
    
    def merge(self):
        print("="*50)
        print("ğŸ”§ FilterFusion - å¹¿å‘Šè§„åˆ™åˆå¹¶å·¥å…·")
        print("="*50)
        
        # åŠ è½½æ•°æ®
        print("æ­¥éª¤1: åŠ è½½å…ƒæ•°æ®")
        metadata = self.load_metadata()
        sources = metadata['sources']
        
        print("æ­¥éª¤2: åŠ è½½å¤´éƒ¨æ¨¡æ¿")
        header_template = self.load_header_template()
        
        print("æ­¥éª¤3: è®¡ç®—æºè§„åˆ™ç»Ÿè®¡")
        source_stats, rule_counts = self.calculate_source_stats(sources)
        self.initial_rule_count = sum(rule_counts.values())
        
        print("æ­¥éª¤4: æ”¶é›†å’Œå¤„ç†è§„åˆ™")
        rules = self.collect_and_process_rules(sources, rule_counts)
        self.final_rule_count = len(rules)
        
        print("æ­¥éª¤5: ç”Ÿæˆç‰ˆæœ¬å·")
        version = self.generate_version()
        
        print("æ­¥éª¤6: ç”Ÿæˆå¤´éƒ¨")
        source_list = self.generate_source_list(sources)
        header = header_template \
            .replace('{VERSION}', version) \
            .replace('{TIMEUPDATED}', datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')) \
            .replace('{SOURCE_COUNT}', str(len([s for s in sources if s.get('status') == 'success']))) \
            .replace('{SOURCE_LIST}', source_list) \
            .replace('{RULE_COUNT}', str(self.final_rule_count)) \
            .replace('{HOMEPAGE}', "https://github.com/Chaniug/FilterFusion") \
            .replace('{LICENSE}', "MIT License")
        
        # æ„å»ºæœ€ç»ˆå†…å®¹
        content = header + "\n\n"
        content += f"! åˆå¹¶è§„åˆ™æ•°é‡: {self.final_rule_count}\n"
        content += f"! æºè§„åˆ™æ€»æ•°: {self.initial_rule_count}\n"
        content += f"! é‡å¤è§„åˆ™: {self.initial_rule_count - self.final_rule_count}\n\n"
        content += "\n".join(rules)
        
        # è®¡ç®—æ ¡éªŒå’Œ
        print("æ­¥éª¤7: è®¡ç®—æ ¡éªŒå’Œ")
        checksum = hashlib.sha256(content.encode('utf-8')).hexdigest()
        content = content.replace('{CHECKSUM}', checksum)
        
        # ä¿å­˜è§„åˆ™æ–‡ä»¶
        rule_filename = f"adblockfile.txt"
        rule_path = self.dist_dir / rule_filename
        print(f"ä¿å­˜è§„åˆ™æ–‡ä»¶åˆ°: {rule_path}")
        with open(rule_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # åˆ›å»ºç¬¦å·é“¾æ¥
        print("æ­¥éª¤8: åˆ›å»ºç¬¦å·é“¾æ¥")
        latest_path = self.dist_dir / "adblock-latest.txt"
        if latest_path.exists() or latest_path.is_symlink():
            latest_path.unlink()
        latest_path.symlink_to(rule_filename)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = (datetime.now() - self.start_time).total_seconds()
        
        # æ˜¾ç¤ºæ‘˜è¦
        print("\n" + "="*50)
        print("âœ… è§„åˆ™åˆå¹¶å®Œæˆ!")
        print("="*50)
        print(f"ğŸ”– ç‰ˆæœ¬: {version}")
        print(f"ğŸ“¦ æºè§„åˆ™æ•°é‡: {self.initial_rule_count}")
        print(f"ğŸª„ åˆå¹¶åè§„åˆ™æ•°é‡: {self.final_rule_count}")
        print(f"â™»ï¸  é‡å¤è§„åˆ™: {self.initial_rule_count - self.final_rule_count}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        print(f"ğŸ” æ ¡éªŒå’Œ: {checksum[:16]}...{checksum[-16:]}")
        print(f"ğŸ“„ åˆå¹¶è§„åˆ™æ–‡ä»¶: dist/{rule_filename}")
        print(f"ğŸ”— æœ€æ–°è§„åˆ™é“¾æ¥: dist/adblock-latest.txt")
        
        # ä¿å­˜æ‘˜è¦ä¿¡æ¯
        print("æ­¥éª¤9: ä¿å­˜æ‘˜è¦ä¿¡æ¯")
        self.save_summary(version, checksum, source_stats, processing_time)
    
    def save_summary(self, version, checksum, source_stats, processing_time):
        """ä¿å­˜æ‘˜è¦ä¿¡æ¯åˆ° JSON æ–‡ä»¶"""
        summary = {
            "date": datetime.now(timezone.utc).isoformat(),
            "version": version,
            "sources": source_stats,
            "stats": {
                "initial_rules": self.initial_rule_count,
                "final_rules": self.final_rule_count,
                "duplicates": self.initial_rule_count - self.final_rule_count,
                "processing_time_sec": processing_time,
                "checksum": checksum
            }
        }
        
        summary_path = self.dist_dir / "summary.json"
        print(f"ä¿å­˜æ‘˜è¦åˆ°: {summary_path}")
        with open(summary_path, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"ğŸ“Š æ‘˜è¦ä¿¡æ¯å·²ä¿å­˜è‡³: dist/summary.json")

if __name__ == "__main__":
    merger = RuleMerger()
    try:
        merger.merge()
    except Exception as e:
        print(f"âŒ åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯: {str(e)}")
        sys.exit(1)
        